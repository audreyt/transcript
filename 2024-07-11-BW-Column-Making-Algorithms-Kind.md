# 2024-07-11 BW Column: Making Algorithms Kind

### Audrey Tang:

We’ve grown accustomed to social media constantly feeding us interesting posts and ads, but we rarely consider that current algorithms are actually steering the world towards anxiety.

Parents of children addicted to smartphones feel this anxiety most acutely. The digital world in which children are immersed from a young age is often shaped by “predictive AI” systems, which determines the information they receive. This frequently leads to social anxiety, boredom, parent-child conflicts, and social isolation.

Predictive AI recommends content based on viewing behavior, using “engagement” as the main metric to amplify content that keeps users glued to their phones. While this may cater to certain preferences, it’s also particularly effective at triggering intense anxiety responses. Audiences worldwide, regardless of age, find their emotional states easily influenced.

How can we address the social problems caused by this type of AI?

Tech giants are now exploring how to diversify the parameters in predictive AI systems, augmenting the current metrics with positive attributes: affinity, compassion, curiosity, nuance, personal story, reasoning, and respect. This approach aims to diminish the impact of extreme content.

Another strategy is to employ “bridging-based ranking,” which uses AI to find common ground amidst opposing views. “Bridging” connects two previously opposing groups by identifying perspectives they both agree on, potentially bridging the divide between them.

For example, X.com and the U.S. version of YouTube have introduced “community notes” features. Contributors can attach notes to contents they find incomplete, inaccurate, or in need of additional context. Notes that both divided groups endorse are presented as balanced reporting, rather than relying solely on view counts.

Over time, online discourse has become increasingly polarized because predictive AI systems amplifies extreme emotions. Those who agree add fuel to the fire, while those who disagree push back even harder, deepening societal divisions. Meanwhile, the internet platforms determining content ranking absolve themselves of responsibility, claiming it’s “user-generated content” and obscuring the harm caused by AI systems.

To change the status quo, we need to encourage more people to voluntarily participate and make algorithms kinder. Only then can we find common ground among divided groups and restore true freedom of expression.

> (Interview and Compilation by Hsin-Ting Fang. License: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en))
