# 2024-07-11 商周專欄：讓演算法變得善良

> (採訪及整理：方歆婷。授權：[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.zh-hant))

### 唐鳳：

當社群媒體不斷推播讓人感興趣的議題、廣告時，我們或許已經習以為常，卻很少想到，當前的演算法，其實正在讓世界走向焦慮。

焦慮感最深的，是有孩子手機成癮的家長。兒少從小沉浸的數位世界，往往是由「預測式 AI」決定其接收的訊息，也常伴隨著社交焦慮、無聊感、親子衝突、人際疏離等情況。

預測式 AI，依據使用者觀看的行為推薦內容，以「黏著度」作為指標，放大讓使用者放不下手機的內容。這或許迎合使用者的某些偏好，但也特別能引發強烈的焦慮反應。全球受眾無論老少，情緒狀態都很容易受到影響。

這類 AI 造成的社會問題，要如何解決呢？

現在科技巨頭在討論的是，如何將預測式 AI 中的參數多元化，改為以親和力（affinity）、同情（compassion）、好奇心（curiosity）、細緻（nuance）、個人故事（personal story）、推理（reasoning），以及尊重（respect）等七種正面指標作為參數，來弱化極端內容的聲量。

其次是運用「橋接排序法」（bridging-based ranking），讓 AI 幫我們找到對立中的共通點。所謂「橋接」，是將原本對立的兩群人連接起來，只要有某些看法是這兩群人都同意的，就有機會跨越中間的鴻溝。

舉例來說，X.com、美國版 YouTube 推出的「社群備註」功能，當使用者認為不完整、不正確或需補充時，都可以在內容下方寫下備註。能讓分裂的兩群人都認同的備註，就會作為平衡報導呈現出來，而非由點閱率掛帥。

回過頭來看，網路言論之所以會激化對立，是因為預測式 AI 將極端情緒的聲量放大，同意的人火上加油、不同意的人更加反彈，社會對立便越來越深。但決定排序的網路平台商，則撇除一切責任，認為這是「使用者自行提供」的內容，掩蓋 AI 所帶來的傷害。

想改變現況，我們得讓更多人自願參與、讓演算法變得善良，才能在分化的人群中，找到共同意見，恢復真正的言論自由。
