# 2024-11-28 商周專欄：AI 巨頭為何願跟對手合作？

### 唐鳳：

最近，我在美國舊金山參與國際 AI 安全會議，分享台灣如何應對合成式 AI 造成的危害。

「安全」是全球 AI 社群最關注的議題之一。過去一年，全球各國政府、業界、學界就針對 AI 安全議題，在英國、韓國舉辦峰會，也促使谷歌、Meta 和 OpenAI、微軟…等 AI 領域的領先業者自願承諾訂定風險門檻，在嚴重且不可容忍的極端情況下，如果該公司無法減輕風險，他們將停止開發或部署其模型和系統。

面對 AI 安全問題，這些科技巨頭並非初次做出自律承諾，但這回可能是它們最積極投入資源，甚至願意與競爭對手合作的一次。

因為輝達晶片訓練的開源模型 Nemotron，表現已經超越 OpenAI 的 GPT-4。最新調查指出，超過四成的《Fortune》五百強執行長會優先選擇開源模型。

相比巨頭們的封閉模型，開源模型不只處理速度更快、能做更多先進應用；如有微調需求，開源模型的更新成本也更低。
 
獲得輝達投資的 Sakana AI 就主張，組合的開源小模型，會比訓練大模型，更能解決企業的問題。如果這份假說成真，大廠的發展空間很可能會受限。
 
這樣的威脅，讓科技巨頭們更在意開源社群的意見。也因此開啟了巨頭們和開源社群，在 AI 安全議題上的合作機會。

畢竟，科技巨頭們花了很大力氣才推出新模型，不希望犯罪者很容易就能繞過模型，產出非法內容，因此跟社群合作，協力維護開源信任與安全工具、快速更新防堵方式。


開放社群也希望集結群體力量，一發現非法內容流傳時，就能快速更新資料庫，而非壟斷在幾家大廠的封閉系統裡。

除了防堵犯罪，兩大社群也開始針對語言、文化對齊有所合作。

相信大家都有用過 ChatGPT，會發現它回應的用詞或句式，往往並不是台灣用法，使用者卻缺乏簡單、有系統的方法告訴 ChatGPT，這句話怎麼講才對？如果能用一套方法蒐集回應，甚至大家可以在這些回應上面批注，讓 ChatGPT 自動對齊我們的文化脈絡。這是開源社群如 C4AI、EleutherAI 注重的價值，也有足以讓封閉系統借鏡之處。

目前開源跟封閉的大型語言模型，誰會更受青睞，還在未定之天。但，不論如何，這都是大廠開始重視全世界各地不同文化需求的契機，讓未來我們使用生成式 AI 時，各地的小眾文化、在地社群，都能獲得平權對待。

> (採訪及整理：游羽棠。授權：[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.zh-hant))
