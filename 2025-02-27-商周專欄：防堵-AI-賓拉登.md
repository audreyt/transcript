# 2025-02-27 商周專欄：防堵 AI 賓拉登

兩週前，我在巴黎參與 AI 行動峰會，開放模型如 Mistral，以及去除審查機制的 R1 推理式模型（如後續的 Open R1、R1 1776 等）成為會場熱門話題。會議尾聲，六十一國集體簽署宣言，承諾以「開放」、「包容」和「道德」的方式開發技術。讓外界驚訝的是，英國及美國均拒絕簽署。

有些人因此誤以為，這是為了追求科技發展，選擇犧牲安全。事實上，恰恰相反。

英國長期致力提倡 AI 安全，全球首屆 AI 安全峰會也是由其主辦。英國政府認為，巴黎宣言沒有充分解決 AI 武器化的挑戰，也沒有提供足夠、實質的明確指引，簡而言之，對國安的關注度不夠。
 
英國的 AI 安全機構，最近甚至從 AI Safety Institute 更名為 AI「Security」Institute。雖然翻譯都是「安全」，但關注焦點不同。後者意味著要更致力於防堵蓄意攻擊，也就是「資安即國安」的概念。


在巴黎峰會上，美國副總統范斯（J.D. Vance）也發表了關於 AI 武器化的嚴正警告。他指出，威權政權正在利用 AI 增強其軍事情報、監控能力以及宣傳活動，對國安構成威脅。他強調，川普政府將採取強硬立場，全面阻止此類 AI 的濫用行為。

在隨後於慕尼黑的演講中，范斯也談到選舉干預的問題。他提到，羅馬尼亞因懷疑俄羅斯利用訊息攻擊操縱選舉，而取消了其總統選舉的結果。他認為，民主國家如果僅因外國的數位廣告就能被動搖，則顯示其民主制度的脆弱性；惟有公民自由表達意見，才能使民主更加強大。

范斯的發言正值 AI 模型快速擴散之際，這類模型可能讓小型行動者以極低的成本發動大規模攻擊，類似「AI 賓拉登」的不對稱威脅。隨著 AI 寫程式、產生具說服力言論的能力飛速成長，甚至超過人類，小規模的攻擊者，也可以用低成本，就做出像羅馬尼亞所受到的境外干預。

在全球嚴陣以待、防範 AI 威脅民主制度的時刻，我在慕尼黑資安會議中分享臺灣多年應對複合式威脅的經驗，具體說明如何與盟友建立協力聯防機制。在國際認識臺灣作為 AI 安全合作的重要夥伴的同時，也是我國資安廠商跟進晶片業者腳步，參與全球 AI 熱潮的大好時機。
