# 2025-04-24 商周專欄：AI 未來學家的 2027 年預言

### 唐鳳：

川普宣布對等關稅，成了全世界最重磅的大事。然而，在矽谷科技巨頭與各大 AI 實驗室，討論熱度更高的卻是《AI-2027.com》——由 OpenAI 前研究員科科塔伊洛（Daniel Kokotajlo）與其團隊推出的研究報告。

任職於 OpenAI 時，他的主要任務有二：

其一，在 AI 技術日行千里的過程預先警示，思考如何在 AI 當駭客、欺瞞人類的能力進步到一定程度前，就搶先防堵。同時，提供有價值的研究方向，幫助 OpenAI 把人力與時間花在正確的事上。

他能在全球最重要的 AI 公司之一，擔當起預測未來的角色，是因為早在 2021 年，他就針對 AI 的可能發展，發表 2026 年預言，絕大多數都命中。

例如，他成功預測 AI 會有兩波重要發展，首先，像 ChatGPT 這樣的對話型 AI，普羅大眾都開始著迷其應用，讓 AI 廣泛落入日常生活；另外是，思考型 AI 出現後，開始產生 AI 訊息危害，甚至，AI 會開始說謊。

其二，他同時也命中美國限制對中共的晶片出口，以及 AI 能在多人互動遊戲裡打敗真人。

過去普遍認為，AI 模型越大，能運作得越好。但科科塔伊洛提出，AI 模型將會在運算過程中停下來思考，不必另外花時間跑訓練素材，就能越來越準確。這概念已經在 2024 年證實：把能源用來推理，而不是只花在訓練上，也可以達到更好的結果。

從 OpenAI 離職後，他針對全球的晶片存量、密度與分布，分析 AI 發展趨勢，推演出可能未來——2027 年，AI 具有欺騙能力，新一代 AI 可能不再對齊人類，而是聽命於舊一代 AI。

他認為倘若各國與 AI 公司都積極競爭，只在乎能否跑贏別人，很可能導致 AI 出現嚴重對齊問題，最終反客為主、成為賽局的其中一個玩家，並於 2030 年脫離人類控制；但如果各大強權在 AI 競爭中，願意持續投資 AI 安全研究，則能避免災難性後果，實現可控制的 AI 發展。

在川普宣布對等關稅前，多國政府大動作投資 AI；如今，資金可能更急著挽救受衝擊企業，這可能讓資源很難投入 AI 安全等防禦性領域。但為了長遠發展，各界更該持續投資在 AI 安全措施，以及運用高品質資料、專注特定產業，生成安全的 AI 小模型，讓 AI 成為幫助人類的助力，而非新增的壓力。

> (採訪及整理：游羽棠。授權：[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.zh-hant))
