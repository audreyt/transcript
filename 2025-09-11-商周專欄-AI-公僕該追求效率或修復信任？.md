# 2025-09-11 商周專欄：AI 公僕該追求效率或修復信任？

### 唐鳳：

今年夏天，我受邀加入牛津 AI 倫理研究院的加速哲人計畫。我最關心的是——當 AI 的速度大幅超越人類時，未來的社會結構該如何應變？

英國政府正積極導入 AI，進入政策、教育、社福等公共服務流程，來精簡公務員人力、減少政府浪費，預估每年節省至少約新台幣一・八五兆元。這也引發爭論：當公部門導入AI審核案件、補助，大眾期待它能屏除私慾，做到絕對公正。但，面對人民的痛苦，它能否保有溫度，做出兼顧情理法的決策？

畢竟，當政策只追逐單一指標時，就容易演變為制度性的冷漠。若是企業提供的 AI 服務不佳，消費者還能切換供應商；但萬一政府公權力不彰，民眾卻難以制衡。

荷蘭就曾發生過 AI 治理的悲劇：稅務和海關管理局嘗試用演算法審核兒童福利，把聽起來像外國名字的個案，與雙重國籍者，作為潛在詐欺指標，導致上千名兒童被錯誤帶離原生家庭，還有上萬個中、低收入家庭遭到審查，錯誤指控詐欺，被要求退還他們合法獲得的福利。

AI 學習能力非常強，在量化目標的設定中，它往往可以找到快速捷徑、人類想不到的方法去達成，而這條路徑卻未思考過衍生的倫理問題。因此，衡量AI成敗的指標，不應只是「效率」，更應該看「損失後的信任」：也就是說，一個好的系統，是在使用者即使權益受損的情況下，依然同意程序是公正的。

社交平台的演算法就是一例，媒體想讓更多人瀏覽文章、分享觀點，會想到的方法是下標更好、更貼近時事，但是機器學習會提高爭議貼文的權重、放大人身攻擊與引戰內容，讓使用者忍不住想互動。因為機器本身沒有倫理觀，只追求流量。這種以單一「互動率」為核心的垂直對齊，最終傷害的是公共討論的品質與互信。

以荷蘭為例，他們可以要求 AI 在砍補助前，先與輔導這些家庭的社工聯繫、檢驗實情。當系統目標不只是節約經費，還要能兼顧讓民眾信任，AI 就必須想出各種方法，爭取民意認同。

目前台灣司法院有一套 AI 量刑資訊系統，面對事實明確的案件，由機器提供量刑範圍，再由法官判斷應酌予減輕或加重。這套系統的優點是透明，當事人、律師或任何人都可以在上頭試算，萬一偵測到偏誤，很容易就能檢舉，避免民眾得把自由、財產交付給一套黑箱標準。

不過，對人類社會來說，並非每件事都能由機器代勞。協助量刑的 AI 系統，也輔佐了台灣新推出的國民法官制度，讓更多國民能以共識決策、賦予重刑判決更高的正當性。在這些關乎生命與尊嚴的議題上，人類的審慎同理，仍然無可取代。

在 AI 高速成長的過程，我們該問的不是「要不要用 AI」，而是「用 AI 來做什麼」。答案很清楚：我們需要的不是效率至上、取代人類的超級智慧，而是能讓全民攜手，擴增集體智慧的協力夥伴。

> (採訪及整理：游羽棠。授權：<a href="https://creativecommons.org/licenses/by/4.0/deed.zh-hant">CC BY 4.0</a>)
