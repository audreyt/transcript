# 2025-10-30 SEWF: Reshaping Tomorrow

# ⛰️✨

Good local time! It really is a profound honor to welcome all of you here in Taiwan, an island of resilience shaped by tectonic plates —

> 4 Million Years.
> Plate Against Plate.
> Taiwan:
> Forever Rising.
> Forever Starward.

— here, tremors remind us daily of the instability of the ground beneath our feet. Yet looking at this room, I feel an energy that is extraordinary: the energy of commitment. Over the past two days, you have embodied our theme, "Shaping Tomorrow." You navigate the cracks, reimagining finance, fostering intergenerational unity, as well as tackling the climate emergency. You're the practitioners of hope.

---
# 💥

Now, I want to begin with a personal story about a crack. When I was around five years old, I was diagnosed with a congenital heart condition. The doctors told me and my family that this child has only a 50% chance of surviving until heart surgery. And after that, every night going to sleep felt like a coin toss. And this instilled in me an urgency and a key lesson that I don't have time to wait for perfection. I adopted a mantra that I call "Publish Before I Perish." I document every lesson that I learned throughout the day, first on cassettes and then floppy disks, and now the internet.

And I learned something profound. On the internet, if you publish something perfect, people press "like," and then they scroll away. But if you publish some half-formed thought, your vulnerabilities, unfinished work, cracks, then that invites participation. People correct, debate, co-create. As the late, great Canadian singer, Leonard Cohen, said, "There is a crack in everything, and that is how the light gets in."

And this is how we in the social enterprise movement understood all along. We see cracks of this world—broken systems, marginalized communities, misaligned incentives—but not as despair, but rather as entrances for light, invitations for shaping tomorrow.

---
# Limits of the Max OS

But we must be honest: in many places around the world today, the cracks are widening, and often they are being widened deliberately. For too long, they are widened by the dominant operating system that has been operating on the instruction of maximization. I call it the Max OS, not macOS, Max OS.

In the economic sphere, it maximized profit efficiency. Of course, it led to growth, but the externalities are inflicted on the people and the planet. Of course, it's been incredibly successful on some abstract number of terms, immense wealth, but it has reached its absolute limits, as we know here, causing environmental crises, geopolitical conflicts, and the erosion of social fabric trust.

And your work, the entire social enterprise movement, has been building the counter-narrative to this extractive model of the Max OS. You're the ones trying to rewrite the code. But much of the world still runs on the Max OS.

---
# Parasitic Engine: Fueling Division

I'll use one example: the digital realm, where the maximizing instruction is applied to human relationships and leading to catastrophic results. Ten years ago, many social media companies switched from a simple thing where we follow the same micro-bloggers, the same bloggers, and we see the same content. They switched to what I call a parasitic engine, parasitic AI, their recommendation system. 

Instead of people following one another, unsolicited content gets pushed to keep us engaged, we're told, to the screen. But then the maximizing OS, when you use it to train an AI, it learns to maximize attention at any cost. And so it learned the best way to do engagement is through enragement. Because if there's something that is building relationships, you see very good content, then you think about it a little bit, maybe you go offline, maybe you start meeting people, and then you don't get addicted to your screen that much. But if there are social divisions that can fuel attacks, if they amplify the extremes, then it sparks outrage, and people get addicted to the screen all the time.

And this has led to an environment of very high PPM. And I don't mean CO2 parts per million; I mean polarization per minute. And so for the past 10 years, we've been living through higher and higher PPM on the infosphere online, creating a headwind against which every social movement, every social entrepreneur is struggling because we cannot easily build consensus on what is happening to the climate, to financing impact, if the entire social fabric has been masked by the smoke of the high PPM. And that parasitic engine paralyzes our ability to do collective action.

---
# Escaping the Hamster Wheel

And now, a couple of years ago, into this already exhaustive system of high PPM, people introduced increasingly powerful generative AI. And again, we're entering now the AI slop era. "Slop" means content free from relational nutrition, optimized not for nourishment, but purely to keep us addicted. And we used to talk about the importance of "human in the loop." But with AI slop, "human in the loop of AI" feels like a hamster in the wheel of a hamster wheel.

The hamster is running faster and faster, maybe feeling great because they need exercise, but has absolutely no steering toward where the wheel is pointing to. And the crucial question now is not whether we should accelerate AI to make the wheel spin faster, or whether we should stop AI to stop the wheel altogether. We need to take control of the steering wheel. So it's not "human in the loop of AI," but rather "AI in the loop of humanity."

---
# Plurality: The New OS

We have been building a new operating system here in Taiwan for a decade because we're very familiar with the intense pressure—environmental, geopolitical, social pressures. But instead of getting destroyed or staying away from those pressures, these conflicts, we learn what I call a geothermal way of facing conflicts.

If you listen deeply to the earth in a social fabric sense, then the friction of differences, the magma of conflict, do not need to be treated as something like a volcano you have to evacuate, but rather you can convert that into co-creative energy. And this engine, I call it Plurality.

This is technology designed not to maximize any one number for any one individual, but rather to strengthen the health of the relationship between people. An AI system trained this way is not following the utilitarian maximizing logic, but rather the ethics of care.

---
# From Outrage to Overlap

Ten years ago, we had a demo, a demonstration of this AI that we call the bridging systems. At the time, Uber was entering Taiwan, and as in the rest of the world, we were facing a lot of conflict, a lot of tension between people who like the sharing economy, convenience, and the people who really want to protect the unions, the taxi workers, and their living conditions.

But instead of getting them dunking on each other on the anti-social corner of social media, which only leads to people hating each other, we built a pro-social media and invited all sides to see each other's feelings. But there is no retweet button, so there's no way for a troll to grow. All you can do is to like and unlike each other's feelings and then share your own feelings.

And then you start seeing in the Polis system that we use, your avatar moving toward people who share your feelings, your community. Then the system makes viral not the extreme sides, but rather anything that is bridging, that gets upvotes from both the left wing and the right wing of the room. And so by making only the bridging ideas viral, after three weeks, we settled on a set of very coherent ideas that together co-created a law for the diversified taxi ride-sharing in Taiwan.

Now, this system is being adopted as an industry standard called Community Notes on X.com, on YouTube, and on Facebook.


---
# Broad Listening

But we can go further now, especially with language models. We can scale the process of listening into broad listening. Last year, another example: Taiwan faced a lot of scams, advertisements featuring Jensen Huang, the Taiwanese NVIDIA CEO. Last March, if you opened Facebook, chances are you'd see Jensen's face trying to give back to Taiwan by giving you free investment advice or free cryptocurrency. If you clicked it, Jensen actually talked to you. It sounded just like him. Probably not Jensen, but a deepfake running on an NVIDIA GPU.

And so at the time, we really needed a solution. But being the most free in all of Asia when it comes to internet freedom, we cannot censor speech. If you ask people individually, they're all like, "the government should stay away from speech." So we sent 200,000 text messages to random numbers around Taiwan asking, "what should we do together?" And they gave us many ideas, and then thousands volunteered. And we chose randomly 447 people, statistically the same as the Taiwan population when it comes to occupation, gender, place they live, and so on.

And so this mini-public, this microcosm, met online in 45 rooms of 10 people each. And they used AI to facilitate the conversation, not as addictive intelligence, but as assistive intelligence.

For example, a room of ten said, "when we display any advertisement, always show it as 'probably a scam' until Jensen Huang or anyone digitally signs off on it."

Another room said, "if somebody lost $7 million to an investment scam that was not signed, let's not fine Facebook only. Let's make Facebook liable for the full $7 million of damage."

Another room said, at the time, TikTok did not have a Taiwan office, so they could ignore the liability, and they said instead of censoring them, "let's gradually slow down the connection to their video so their business goes to their competitor, but we're not censoring speech; we're just modulating reach."

---
# Uncommon Ground

And so these ideas, taken together, form a very coherent package. And we used a language model to weave them together. Because if you have done a facilitated assembly, 45 facilitators mind-melding takes literally a week. But using a language model, the 45 rooms actually wove together the coherent package just in the afternoon, and people voted on it. So this is the uncommon ground.

They discovered common ground between people, across all their communities. And then over 85% of people said that this is a very good idea, and nobody was very unhappy. And this sign of public will convinced the parliament. So that was last March. By May, we sent in all the law changes, and by July, all these were passed. And so this year, if you scroll on Taiwanese social media, you simply do not see those deepfake advertisements anymore. It's down by more than 90%.

So this is the geothermal engine in action. It demonstrates that no matter how much conflict, how much heat we have on controversial issues, emerging harms, we can use AI to foster deep and broad listening and foster uncommon ground between people.

---
# Plurality for Planet

And these tools are vital for the work that we do every day on the planet as well. Because the climate crisis and the transition to the circular economy demand unprecedented levels of coordination, managing common resources—atmosphere, oceans, biodiversity, and so on.

So this kind of engine can translate communities that use very different metaphors for the same underlying issue. Maybe one side talks about climate justice. Maybe another side talks about creation care because they are spiritual. Previously, on the anti-social corner of social media, they'd attack each other. At best, they'd ignore each other.

But using this idea of uncommon ground and bridging systems, for the first time, we're able to build pro-social bridges that translate between these different ideas, different dictionaries, synthesizing them into resilient policy.

---
# Open Ecosystem

Now, for this vision to thrive, the system I just described needs to be open, transparent, and locally governed. We cannot build this bridge on closed, proprietary, colonizing infrastructure. We need to build a digital public infrastructure, DPI, based on the equivalent of public roads, bridges, and parks. It should not be owned by a single corporation. It needs to be a shared resource based on open protocols.

Think about email or podcasting. Many podcasts end with "join us wherever you get your podcasts." This works because podcasts are built on open protocols. This interoperability prevents lock-in and fosters a healthy ecosystem.

But the current digital landscape often lacks such openness. We're like drivers on the information superhighway of social media with no exit ramps. In many places, platforms make it very difficult to take your relationships, your connections, your communities, and move elsewhere. Fortunately, this is now changing. Just like when you switch a telecom provider, you can keep your number — number portability.

There are a number of jurisdictions, such as the state of Utah, that has already passed and is now preparing for next July where you can take your account from, like, X.com into Bluesky or Truth Social, and the old network is legally required to keep forwarding new likes, new reactions, new friends to the new network. So switching away does not cost you your community. And now we're working with the European Union and also with the senators in the US to make this the norm also for AI systems, so that the human context, the terms of service, is set by the community, not by the monopolists.

---
# Kami: AI with Care

And so this brings me to the vision of the AI future that we are co-creating. Some of you know there is a dominant narrative about artificial superintelligence this year. It is frequently envisioned as an all-knowing, all-centralized intelligence, a Skynet, a false idol, and this has led to anxiety about control. But many of you here, I think, would love to see a different, positive vision in the work that we all do, in the wisdom of the Indo-Pacific, Austronesian-speaking population.

I was just in Japan. In Japan, they have this tradition called Shinto. And the Shinto gods are not like the super-intelligent god. They call them *kami*, which is a local spirit of a forest or a river, and just cares about the relationship around that place. In Taiwan, we say Tǔ Dì Gōng or Tǔ Dì Pó, which means more or less the same idea: a spiritual local steward. And so if we train an AI system not to optimize one single number, but rather to be attentive to the relational health of this community, this river, this forest, then it is bounded by the place, the culture, and care.

And now in Oxford, through the Institute for Ethics in AI, we're now training AI agents as stewards of such relational health. They're localized, they're symbiotic intelligences that are not parasitic. And the reality is that many of the leading frontier corporations are on board with this vision. 

Just yesterday, a major step was taken toward this future. With my team at ROOST, the Robust Open Online Safety Tools Foundation, OpenAI made a groundbreaking move of open-sourcing its Safeguard, the core safety model. The engine that currently protects hundreds of millions of people every day is an active, beating heart of OpenAI. But what makes it revolutionary is that OpenAI is giving up control. By making it an open model that runs on your phone—it's a very small model—it can act as a local steward. The core feature allows any organization, any social enterprise, any community to bring your own policy, BYOP.

That means that climate justice or creation care, spiritual or communal, a child's educational platform, a climate action debate forum—each of them can have the same powerful engine but with very different, unique codes of conduct, a distinct sense of care. And we can create thousands of digital local *kami*, each attuned to the specific needs of the community, to synthesize, to summarize, to create the uncommon ground, and more crucially, to link across different communities.

And I think all of you are local stewards to your communities, and the superintelligence we need is not a machine. It is all of us. We are the superintelligence we've been waiting for. And it is our collective capacity to coordinate, to care, that can steer this future together.

---
# Building Civic Muscle

Now, of course, there are a lot of dangers in trying to steer away from the maximizing OS using AI as a facilitator. One impulse I hear from many policymakers is they will say, "Oh, let's then just ask a chatbot to interview people for a few minutes, and then we'll have those chatbots debate with one another and then create policy." And they have this kind of machine; they call it a Habermas machine.

But if we just design policies this way, using proxies of ourselves, it would be like sending our robots to the gym to lift weights for us. I'm sure they're very impressive, they can lift a lot of weight, but our civic muscle will atrophy this way. There's no way we can exercise our care if we simply delegate to those dyadic chatbots that maintain only one-on-one relationships to people while overlooking—kind of like a team coach or facilitator—the team, the group dynamics.

And I think we as social entrepreneurs have known this for more than a decade. We're the global civic muscle. And we have done a lot of the difficult, relational work for change. And it is time that we set this as the norm for AI conversations.

---
# Writing the Air 
# — Together

In Japan, they have this notion of "reading the air," which is quite resonant in a lot of Asia. It's about understanding the unspoken social context and adapting to that context. But I think we're past the point of simply just reading the air and figuring out our theory of change. The air, as I mentioned, is polluted by high polarization per minute. The fog is very thick.

I think it is time for us to collectively "write the air." 

We must shape the norms of the new economy and tech landscape by demanding AI agents that prioritize bridges over divisions.

We must demonstrate through our actions that collaboration outperforms extractive logic, and we need to infuse the values of interoperability, sustainability, deep democracy into the very code—not just the software code, but also the regulatory code, the cultural code—of our shared future. 

Because we're at a turning point. The old system, the Max OS, is already crackling under tremendous pressure, and people are looking for a new operating system.

So we can remember the lesson of the geothermal engine: that pressure can be transformed into people power. And the cracks that the old system is showing—that is how the light gets in. And you are that light.

---
# The Plurality is Here

To close, I offer this poem, this prayer, a vision of our work together. Ten years ago, when I became Taiwan's Digital Minister—*shùwèi* means both digital but also plural, so this is my job description—it goes like this:

> When we see internet of things,
> let's make it an internet of beings.
> When we see virtual reality,
> let's make it a shared reality.
> When we see machine learning,
> let's make it collaborative learning.
> When we see user experience,
> let's make it about human experience.
> When we hear the singularity is near —
> let’s remember: The Plurality is here.

Thank you so much.

**Q&A**

### Emily Wu:
Thank you, Audrey. And as we move into our Q\&A, commit to change that will stay so we can be in this space. And for our participants here, by the way, also online, now get your phone up or client chat box and start asking questions. We'll start pulling questions from the Q\&A. Thank you, Audrey. That was a lot in 20 minutes, from Leonard Cohen to participatory governance to the *kami* values. Thank you so much.

Thank you. The first time I interviewed you, you were a Minister without Portfolio at the time. This was when Taiwan was the star around the world. And you had gotten pulled into government work because you were somebody who was able to bridge—you came from the hacking community, but you also knew private sector very well. And you were going to take those two and have them work with the government.

### Audrey Tang:
That's right.

### Emily Wu:
Which is something—it's magical, because it's very aspirational for everybody here to be able to influence policies like that. So today, in the next 20-30 minutes, we want to talk about government, changing policy, we want to talk about technology and the future. So you are such a rare, rare talent. First of all, you gave a taste of what you bring to the system. But first of all, how do—for the rest of, for everybody here who will then go home to their communities—how do they find a "you" from all the quarters of Earth, for the different government systems? Or maybe somebody like you to work with private sectors? How do we begin to identify people like you who we can then work with?

### Audrey Tang:
That's a great question. Thank you, Emily. So for the past ten years, I have been publishing on the SayIt platform in public domain every interview, every lobbyist visit when I was minister, all the internal meetings that I chair. And because of this, all the language models are trained on the thoughts that went through my mind and became part of the transcript—more than 2,000 of these with me. And so if you ask that question to any of those language models, they can answer at an extremely high fidelity of how Audrey would answer.

And the most frequent quote for that question would be that I was at the Lagrange point between the government on one side and the movements on the other. So a Lagrange point, for the non-astrophysicists, is the point between two celestial bodies, like the Earth and the moon, and there are some satellites parked there. And in this place, they're not pulled into this orbit or that orbit; they're in the middle. I always say that I don't work *for* the government, I work *with* the government. I don't work *for* the people, I work *with* the people.

And so it is something that anyone can cultivate. If you embrace the words, the ideas, the main spirits of two different celestial bodies and focus not on co-opting one or the other, but on translating with one another—like climate justice and creation care—then you can also cultivate this way of bridge-making in your own mind. And so I would encourage any community to try this kind of deep listening session where you just hear from very different factions and then try to repeat back what you have heard and practice this communication, this bridging. And then anyone can cultivate and become in the Lagrange Point.

### Emily Wu:
Let's walk us back to the time of your involvement, both as Minister without Portfolio and then as Taiwan's first Digital Minister. How did you begin to design an efficient system with accountability that's without bureaucracy?

### Audrey Tang:
Yes. Well, first of all, bureaucrats are my friends. I entered the government saying that I'm a public servant for the public service, meaning that I never joined any political party. I never attended any party rally. I'm fiercely all-partisan. Okay. And so that means that the bureaucracy was able to internalize this bridging, Lagrange point logic by taking on reforms that save their time—like reducing tax filing from three hours to three minutes—without incurring more risk. Or it can reduce their risk—like overcoming the Uber problem, the deepfake scam advertisements, and so on—without wasting their time. But bureaucracy was probably already at a local optimum of the trade-off between risk and time. They're very good at making trade-offs.

So what made me so good at breaking this trade-off and introducing improvement? Well, it turns out it's not my idea; it's people's ideas. By opening up to the public domain all the meetings that I participate in, people understand not just the "what" of policy, but the "why" and the "how" of policymaking. So I get a lot of, well, trolls and personal attacks, of course, but then I also practice "troll hugging." So every time I receive, like, a thousand words of very vicious personal attack, with the help of language models, I ask the digital audience to find the five words in that rant that they can construe as constructive, and then respond only to these words. And using this is a geothermal engine that turns magma into energy.

And then, most people are so trollish because they were so close to the pain and they're fed up with being systemically ignored, sidelined, marginalized by the bureaucracy. So these people, if you can hug them, hug the trolls, actually do have notions of the solutions that you can then bring to the bureaucracy. So by building this kind of exoskeleton of troll hugging and practicing Aikido for more than, I guess, 100 collaborative meetings this way, inviting trolls in through the cracks, letting the light in, then we rebuilt the trust. The approval rate was at 9% in 2014, but by the time we first met in 2020, it was over 70%.

### Emily Wu:
We're very lucky here to be sitting in Taiwan where we can ask for accountability from the government, to be in a thriving democracy as such. Many of us today are not from countries with such thriving democracy, or for some watching online, what words of advice would you have for social entrepreneurs working in authoritarian states? Or the range of different authoritarian states.

### Audrey Tang:
Well, we were born into an authoritarian state, right? We have the same birthday.

### Emily Wu:
Yes.

### Audrey Tang:
Yeah. So in '81, Taiwan was devoid of the freedom to form new parties. It was devoid of freedom of running your own newspaper, no legal way to have political change through electing our president. We were under one of the longest decades of martial law. And so we know something about authoritarian states.

But even during the '80s, before the lifting of the martial law, we already saw social entrepreneurship with the forms of co-ops—consumer co-ops were very large back then in the '80s. We saw charities with a renewable revenue model. We saw many spiritual institutions working to build what we call cognitive security, fact-checking and so on, but not on political matters because we were still under martial law, but rather on simple things like consumer rights, food and drug safety. If this food plus that drink, would it cause cancer? Maybe not. Right?

So all these grassroots ways to build more legitimacy than the authoritarian government eventually, when Taiwan democratized and we finally voted for our president in '96, all the initial politicians needed to pay more than lip service to the social sector, to the plural sector, because they were the ones that enjoyed much higher legitimacy than the political class at the time. So my advice is to start hyperlocal, to start communal, to use exactly the same methods we talk about—radical transparency, bridging, broad listening, and common ground—but starting from the solidarity economy, from social entrepreneurship, for the civic health, if not the democratic health.

### Emily Wu:
And bridging that to technology, do you have examples of some of these spaces in the world where there's more limited space of how to push progress, but they're leveraging technology to their advantage? Do you have examples of that to show that someone can maybe learn from and be inspired from?

### Audrey Tang:
Well, in a sense, I wouldn't call myself a tech progressive. I would call myself a tech communitarian. That is to say, technology to foster the relationship of people in a community on the terms of that community, instead of trying to make progress but sacrificing some communities for some other communities.

So I think in Taiwan, one of the main things is that when we say "sovereign AI," it doesn't mean what some other countries say by sovereign AI: a national model to essentially marginalize the vulnerable populations within our nation. Because we're a transcultural republic. And so we work with all the 16 indigenous nations and their language variations. We work with the sign language community, which is also a national language. And so our sovereign AI is really civic AI.

And so if you look at the Taiwan AI strategy, the National Development Council and the National Development Fund invest in more than 150 small civic models, each uplifting one particular culture, one particular sector, or one particular community. And I think this idea of aligning AI to particular communities is really gaining ground. I was just in South Korea, and they want to be the G3, the third largest in terms of AI. But the way they talk about AI models is again starting from the communal needs and trained on very energy-efficient models so it can react to the actual civic context of the local people, steered by the local people, without having to wait for six months and very long electricity training and so on.

So I think this is really something like a public AI, a civic AI network that all the different communities are tapping into, and this is something that I would sincerely welcome social entrepreneurship to join, no matter where you are, because this is not a progressive thing. This is a communitarian thing that preserves, conserves if you will, the knowledge, the wisdom of each and every indigenous nation, community, culture, and so on.

### Emily Wu:
There's a lot of push for AI, a lot of push, whether it's from not just from the investment side, the technology side. And I think for some of us, you can not work with AI, right? You can continue to work as is. AI can be very scary with deepfakes, with disinformation, but what we're continuing to hear is that push for AI...

### Audrey Tang:
I distinguish between addictive intelligence, which again runs the hamster wheel, so there's no way for you to steer, even though a human is in the loop. But the only thing we can get is more addicted. But we also have assistive intelligence, which if you don't like how it works, you have absolute control, steering with your community, like a maker spirit. And I think these two lead to very different futures.

The addictive intelligence future is that of gradual disempowerment. At every juncture, we may feel a little bit relaxed, kind of chill, you know, AI, the robots help you lift the weights, sounds good. But then eventually it removes human agency entirely from the equation. On the other hand, the assistive intelligence makes it very easy for communities to steer their own local norms. One very quick example: the Mozilla Foundation runs this idea called Common Voice, where people can record their local language in their local speech, and together they train this speech model that is not just accurate but sensitive to the cultural nuances. So instead of people having to train to speak perfect Mandarin or something for Siri, they can actually bring the AI agents and assistants to their local language. And all you need to do really is just to contribute and to read some of your personal stories and so on, and then to check each other's readings. So this kind of data collective already works, is already empowering many lower-resource, global majority languages to take back control of their own languages, instead of being lifted from their local community on an individual basis to speak perfect English or perfect Mandarin.

### Emily Wu:
That's a lot of training and a lot of data. What do you do with that data afterwards? How do you consider privacy in the new era?

### Audrey Tang:
Yes. So as I mentioned, the digital public infrastructure, or DPI, needs to come with a digital privacy infrastructure. And the privacy infrastructure that I'm personally very excited about is called meronymity. It's an interesting word. *Mero-* means "part." So meronymity means partially real name and partially anonymous. Previously, in the analog world, if you want to prove that you are over 18 years old, maybe you want to rent a car or buy some substance, then you reveal your ID, which contains not just the fact that you are an adult, but also your birthday and your name and your address or whatever. Right? It reveals too much; it's the over-collection of private data.

But now with meronymity, like in the Taiwan digital identity wallet, you can make a proof called a zero-knowledge proof that only proves, attests that you're over 18 or over 16 or however old is required, but it doesn't say anything about your birthday or birth year. And you can also make a proof that you are a resident of Taipei without revealing your address or your name. And so this enables each aspect of us to participate authentically in communities and offline transactions, but without sacrificing our privacy, without getting doxxed from the internet. And so this switch from identities to credentials—selectively disclosed verifiable credentials—I think is absolutely key if we are going to run data coalitions, data cooperatives that take the data future into community hands.

### Emily Wu:
So that's a great scenario you just outlined, but for many companies who work with customers or suppliers, we are also collecting a lot of data from the general public. So do you have a bit of a checklist for us? You know, how do we make sure that the data we're collecting, that we are storing it, using it responsibly? What is that checklist? What is your go-to? Is there an online resource, or can you just tell us for us?

### Audrey Tang:
Yes, certainly. So of course, there are online resources like the Electronic Frontier Foundation, EFF, has been making scorecards for more than a decade. And here in the Ministry of Digital Affairs, we also publish the privacy-enhancing technology, the PET guideline. And there's probably privacy technology guidelines elsewhere in your jurisdiction as well.

And they are all converging on a very important idea, which is to bring the compute to where the data is, instead of asking data to be extracted to where the compute, the code, are. Okay? So the idea is not that we simply trust ChatGPT or Gemini or whatever to process all this data, but rather to make a smaller model that can run in the community infrastructure, and you can then verify that it has no connection at all to the outside world when it processes the data, but then it can still share the learnings through federation and so on to other plots, learning about things in the data without revealing the doxxing privacy information of the raw data. And so this kind of privacy technology is getting better every day, and I encourage you to check them out.

### Emily Wu:
I wanted to ask, I think you've covered a lot of it. A lot of it is just, you know, how do we as social enterprises use technology for good? Is one of the big things that I think is on everybody's mind when we walk away today. But you touched a lot on that. So I'll change that a little bit, is, you know, how do we convince those not in the room to make technology for good? It is a choice. We would like everybody to be socially responsible in the work we do, but there are other priorities that some choose. But for those who are not in the room, what do we tell them? How do we... what do you tell them to convince them?

### Audrey Tang:
Well, I want to push back a little bit here because it's not often a choice. If we are in a place of market failure, it is a race to the bottom of the brainstem. There is simply no choice that can flip the game unless you change the rule of the game.

One quick example: a couple of years ago, there was a study that showed for an average US undergraduate using TikTok, if you want to convince them to move off TikTok, you will have to pay them on average $60 per month. So they lose that much utility if they go cold turkey on TikTok. However, if there is a magic button they can press to move everybody they know also off TikTok, they're willing to pay you $30 per month for that to happen. And so in a normal market, that shouldn't happen, right? But this is not a normal market. This is a product market failure. People are squeezed into TikTok not because they enjoy it, but rather because everybody else was also there, and then if you quit, you lose the community. It's an extractive model.

And so a simple reform, as I mentioned in Utah, that says if you move away from TikTok to anywhere else, you can keep all your social connections, all your likes, your followers, your audience. That simple law changes the incentive so that people not in the room do not have to be convinced. The economic incentive flips so that they have to now fight to provide better quality of service to keep their customers. There are many, many issues like this that can be resolved quite simply by forced interoperability and portability. The Data Act, the Digital Markets Act in the EU, and many other laws are now looking at this, I think with a fresh angle, because the old way, which is just to moderate away troublesome content, is now falling out of favor since the communitarian turn, let's call it that, in the US. And therefore, building off-ramps and on-ramps is now the go-to solution for many jurisdictions, including the US.

### Emily Wu:
So let's unpack that a little bit more. How do you... you're telling them it's not a choice. People don't like to hear that. They like to hear that "I have a choice, and I'm making the right choice." How are you convincing somebody else to make that choice without telling them "you don't have a choice"?

### Audrey Tang:
Well, my point was that before the Digital Choices Act, before number portability, then if you're a social network, you don't really have a choice other than extracting from your customers because it's a race to the bottom. Just like before number portability, if you switch telecom and you cannot take your number, then there's no choice for the upcoming telecom to compete for the mindshare and for the customer share.

So my point was not that entrepreneurs do not have a choice. My point was that policymakers need to design the framework such that it creates choice in the market away from monopoly power. In a monopoly situation, of course, you do not have a choice. But once the market corrects itself and creates the off-ramps and the on-ramps in the digital realm, then it restores choice for everyone. So that is, I think, my main message. And if your policymaker says that this is not possible, then just point to Utah and point to many other places that are already experimenting with very good results—forced interoperability.

Point at Taiwan, where we have mandatory liability for unsigned scam advertisements. These liability mechanisms do work. Facebook, after getting fined for almost 20 million NT dollars under this kind of law that was crowdsourced by the people, did change their behavior now in Taiwan. And so I think the way that we can write the air to let the entire society and the policymakers know that people, regardless of their political party ideology and so on, are in favor of these new policies of digital interoperability and portability—that can send a very clear message to policymakers.

### Emily Wu:
So getting the policymakers to make that change.

### Audrey Tang:
Yes. And so for it to become a matter of common knowledge for policymakers.

### Emily Wu:
Exactly. Now we're back to policy then, which is really, really, really important here. So what might democracy look like in a digital space?

### Audrey Tang:
Well, I think small-d democracy is really important here. So there's big-D Democracy, like Democracy as a polity, as a way to elect presidents, as a way to elect members of the parliament. This is our big-D Democracy. And as all of us know, it's in decline. Last year, we have seen many, many elections around the world, half of the population in democracies, and not a single ruling party retained their original amount of majority. Some of them are still ruling parties, but all of them lost some seats. And they lost seats not to the traditional opposition party; most of those also lost some seats. They lost the votes to the more polarized, more radical, more fringe ideas, which are now very quickly becoming not so fringe.

And so my point here is that it is through small-d democracy, the everyday democracy, civic relational health, that we do every day in schools, in community centers, in local, hyperlocal towns, districts, and so on, that we rebuild the civic muscle, the relational health that can overcome this populism turn, that can make us more popular than even the populists. And this has happened in Taiwan.

Around six years ago, I believe, Taiwan had a wave of populism. We had a leader, a populist leader, very famous with especially elderly people, like my aunts and uncles. And he really became not just the Kaohsiung mayor, but rather ran for president at the height of populism. But because we have very strong civic muscle that can point out if he did not work the way that the people, the population that elected him in the first place, it can also send a very clear signal by not just recalling him, but also showing where the population is actually thinking.

And so, he thoroughly reformed. Speaker Han Kuo-yu of our current legislature is now one of the most moderate politicians in his party. And I would say that, he now also chairs the Taiwan Foundation for Democracy and really has depolarized relational health, civic care, as his main agenda through the TFD. And that was because we have strong enough civil society, the social and plural sector, that can send these kinds of clear messages that are more popular than populism. Populists need to reform.

### Emily Wu:
But I keep looking back, looping back to some of our colleagues who either they are more risk-averse because of their communities or literally they cannot be pushing for such progress. And the point you made about your example with Taiwan before martial law was lifted and some of the opportunities that lie there... to bring it back to the risk-averse societies also now, as you said, in some of the previously more thriving democratic nations where it's more... it's dangerous to speak up now. So where are the opportunities for social enterprises now, do you think, going forward in the next foreseeable future?

### Audrey Tang:
Well, I mean, I can speak freely, right? So in Bowling Green, Kentucky, we worked with the people there in a hyperlocal way. And there are just, I think, 10,000 people next to Nashville. And many conversations can feel very polarized. The Democrats and the Republicans, as I mentioned, they may speak about the same thing, but because they use very different words, it often feels like they're really talking past each other, if not really shouting at each other. But by using Polis, the bridging system, in the experiment we called "What Could Bowling Green Be?"—the people reacted to each other's feelings about how to make Bowling Green better in the year 2050, so very open-ended.

And people proposed many ideas. Some of them didn't get a lot of votes. For example, "let's put red carpets on all the walkways"—that didn't get any votes. But some of the things, for example, making the cultural identity distinct from Nashville and so on, got a lot of buy-in. At the end, more than 80% of ideas got surfaced as actually the uncommon ground. So the uncommon ground was actually much larger than the 10% on the extreme left and 10% on the extreme right. Most people do agree with most of each other on most of the things. At the time, there was just no group selfie, no machine that can turn the geothermal heat into this kind of momentum going forward. And so using a language model, open-source ones such as SenseMaker, they were then able to weave together the community spirit on this 10,000-people scale very quickly. And now we're working with the Napolitan Institute in a project called We the People 250, and that is the idea of using the Bowling Green model but in each and every congressional district in the United States of America, showing again, most people do agree with most of each other, even though they use different words to describe these ideas. And so if you can depolarize one of the most advanced states of polarization, then I'm sure that the rest of the world can also steer toward bridging over polarization.

### Emily Wu:
We're really lucky today to have somebody who has worked in this cross-sector, and so we can talk about advice but also case studies and examples from each and every field we do. We are coming to the end of our panel, but I really do encourage everyone to continue to make use of the app and the community boards on LinkedIn, on Twitter, and to engage with Audrey. She writes back to everybody.

### Audrey Tang:
A language model on my laptop drafts it, just for full transparency, but I read everything that it writes before hitting send.

### Emily Wu:
But we're really lucky to have that. But I do believe that you are not the only person—we know you're not the only person in the world. We're lucky to have you today. But I so encourage you to find the Audrey of your community and to work with that person because they really are the key to unlocking the kind of inner relationships between the different communities and to lead all the way back to policy for change. And I would like to invite you for a final remark. Perhaps it's on a message on building consensus going forward, or maybe it's a challenge to policy leaders.

### Audrey Tang:
Certainly. As I mentioned in my talk, we the people are already the superintelligence that we are looking for. The augmented collective intelligence—ACI, I think, is a much better vision than AGI, artificial general intelligence. And if we can all amplify our collective intelligence, I think people will see that we have much more in common despite the illusion of polarization in the online world. Then we will be able not just to read the air, as I said, but to write the air together and free the future together.

### Emily Wu:
Thank you. In the spirit of transparency, will you have your speech online somewhere where we can go back?

### Audrey Tang:
Sure, of course. It's on the SayIt platform, as I mentioned. And the SayIt platform actually is something you can not just read, but write and own because all of it is in the public domain. And so if you take some part of it and publish a book and call it your book, I'm entirely fine with that. This is what I mean by "publish before I perish" and being a good enough ancestor.

### Emily Wu:
Thank you. Thank you so much.

