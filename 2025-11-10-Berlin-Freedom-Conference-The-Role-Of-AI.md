# 2025-11-10 Berlin Freedom Conference: The Role of AI

### Audrey Tang:

> (We the People are the Superintelligence)

Good evening, Berlin. It is such an honor to be in a city that proved to all — when people link arms — even walls can fall.

Berlin is the perfect place to dialogue on AI, because the lesson of 1989 is simple: When the people co-create, they outperform any master plan.

I wish to share my thoughts on how we move from addictive intelligence to assistive intelligence, from extractive platforms to protocols that foster relational health.

I propose that the most important frontier model is not found in a lab. It is us — our augmented collective intelligence — we the people.

> (A Crack, and a Lesson)

When I was five, a life-threatening heart condition taught me urgency. I adopted the mantra of publishing before perishing, recording what I learned each day. And I discovered something profound.

Perfection invites applause. But imperfections, imperfections invite participation. Our cracks are openings for collaboration. As Leonard Cohen sang, “There’s a crack in everything, that’s how the light gets in.”

For democracies, this is key: We must publish our process, not just our final policy. When the people see the “how” and “why,”  critics become co-creators.

> (Max OS vs. Plurality)

Let us call the dominant logic of our digital age the Max OS. And no, I do not mean Apple’s macOS. I mean an operating system that maximizes engagement, watch time and clicks.

In our social systems, Max OS creates parasitic recommendation engines. What is the best way to keep our attention? Fueling outrage. The result? Very high PPM, or polarization per minute.

Ten years of maximizing engagement morphed our social feeds into adrenaline fabs. It rewarded the extremes and punished the nuances. This environment of fractured trust is exactly what authoritarians exploit. Now, add generative AI to the mix and we are flooding the zone with “slop” — content with zero relational nutrition.

So, the question is not “Should we accelerate or stop AI?” The question is “Who steers AI?”

> (Steering, not Spinning)

Right now, if we are the “human-in-the-loop” of that parasitic wheel, there is no control. We must move from “human-in-the-loop-of-AI” to “AI-in-the-loop-of-humanity.”

What does this mean? It means we take control of the steering wheel. We use AI as assistive intelligence, not addictive intelligence. We use it to help find the overlaps that turn conflict into geothermal energy for powerful co-creation. 

The metric we should maximize is relational health, trust, inclusion and the speed at which we can transparently correct our mistakes. And if we can accomplish this, we can free the future — together.

> (Outrage to Overlap)

In Taiwan, we know all about pressure. We are the number one global target for polarization attacks. But we adapted. We learned to replace “anti-social” media dynamics with “pro-social” architectures. We now use tools where you cannot quote-tweet just to dunk on someone. Instead, statements are assessed as to whether they resonate across divides. The ideas that go viral are not the extremes, they are the ones that bridge left and right — the "uncommon ground" at the heart of the Taiwan Model. 

When ride-sharing came to Taiwan ten years ago, it triggered intense conflict amid many segments of society. So, we used bridging systems — widely used today as Community Notes — to map where the people actually agreed. In just weeks, we turned that conflict into policy options that most people could live with. I call this the “up-wing consensus.”

> (Freedom Architecture)

Berlin builds bridges, Europe promotes interoperability and portability. This spirit enables the exit of a social system with your data and social graph, just like you keep your phone number when you change carriers. This is freedom architecture.

We must safeguard freedom of movement online by resisting digital colonialism. Policy is catching up to the reality that platforms are places. The Data Act gave us data portability, the Digital Markets Act, interoperability.

Let us extend that spirit. We need protocols for freedom of movement, for association, for deliberation, for safety. Think of them as public roads, bridges and parks not private, walled gardens. Because when an exit is real, platforms must compete on care, not on capture.

> (Digital Resilience for All)

Authoritarian playbooks are global. Spyware. Troll farms. Transnational repression. Our responses cannot just be “takedowns” after the harm is done. They have to be “prebunking.” They have to be safe by design.  

What does this look like? First, selective disclosure: It means you can verify only one part of your credentials that is relevant — like “I am over 18” or "Ich bin ein Berliner” — without revealing your identity.

Second, edge AI: Smart defenders that run on our device, safeguarding our community. Third, bring your own policy. This means our local safety rules, our deliberation norms, they move with us across the web.

Such an approach is critical in rolling back transnational repression. We can use AI to detect patterns of harassment, but we let the community’s code of conduct make the final judgment. Nothing about us, without us, must be the principle of our architecture.

> (6-Pack of Care)

Forging stronger democracies is not easy. We need to see the process as working out in a civic gym with a care loop. 

There are six basic moves: Actually listen to people; actually keep promises; let people in on the process, then check the results together. As win-win as possible — and as local as possible.

Training AI this way moves beyond maximizing a score or following a rule. This is relational alignment. We align with a process of care. Because, if we delegate democracy and policies to chatbots for debate — like sendings robots to a gym — our civic muscles will atrophy. 

> (⿻ Plurality is Here)

The superintelligence we need is not a machine. It is our capacity to coordinate with care.

We the people are the superintelligence.  

When we see Internet of Things, let’s make it Internet of Beings.  

When we see virtual reality, let’s make it shared reality.  

When we see machine learning, let’s make it collaborative learning.  

When we see user experience, let’s make it human experience.  

And when we hear the singularity is near, remember, the Plurality is here.

Thank you for your generous and kind attention. Live long and … prosper.
