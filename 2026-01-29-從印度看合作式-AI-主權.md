# 2026-01-29 商周專欄：從印度看合作式 AI 主權

### 唐鳳：

國際 AI 峰會今年二月即將在印度登場。作為曾經的全球軟體後勤辦公室，印度此刻的處境充滿了矛盾與張力，這不僅是單一國家的轉型陣痛，更是所有中型強權（middle powers）共同面臨的縮影。

過去三十年，印度憑藉龐大的工程師紅利，與矽谷建立了深厚連結。然而，生成式 AI 的浪潮正在重新定義「軟體代工」的價值。

二〇二五年七月，印度軟體巨頭塔塔諮詢服務（TCS）啟動了歷來最大規模的人力調整，將裁員逾 1.2 萬人（約佔總員工 2%）。這並非單純的衰退信號，更像是產業升級的警鐘。傳統的代工模式正在瓦解，企業必須騰出資源，轉向高價值的 AI 解決方案。這場裁員潮顯示，印度正試圖在舊模式崩塌前，奮力完成「大象轉身」。

在行動網路時代，印度政府打造了引以為傲的數位公共建設「印度堆疊」（India Stack），透過統一支付介面（UPI）與身分認證（Aadhaar），成功迫使 Google、Meta 等巨頭必須遵守在地規則才能進入市場。

然而，AI 時代帶來了新的規則破壞者。當使用者習慣透過 AI 直接獲取答案與服務時，過去建立在 App 介面上的流量入口與協定防線，面臨了被繞過的風險。這不是印度堆疊的失敗，而是戰場維度發生了改變。防禦工事還在，但對手從「雲端」直接空降。

去年，在缺乏本土頂級基礎模型的情況下，印度新創圈出現了務實卻危險的傾向：大量採用 DeepSeek 等模型。這反映了中型強權的普遍困境：在缺乏本土算力支援下，這是少數能讓產品快速上市（Time-to-market）的手段。

但這選擇並非沒有代價。資安大廠 CrowdStrike 曾深入分析 DeepSeek-R1，指出模型內嵌的「隱性導向」可能構成資安漏洞。報告顯示，當測試場景涉及特定政治敏感群體（如維吾爾人）時，模型生成的軟體架構會出現異常的高漏洞率。

這類湧現的模型偏差，直接影響程式碼安全性與穩定性。當下游軟體商使用這些受污染的引擎，偏見就隨之擴散到整個應用體系。

以印度為鑑，既然中型強權無法獨力訓練出頂級模型，各國更應集結算力與高品質語料，建立像公共圖書館一樣的公共模型，從通用模型出發，有系統地糾正認知偏誤，並針對在地文化進行深度對齊，在不依賴特定資本的前提下，擁有自己的數位大腦。

臺灣具備晶片優勢，不妨積極與全球攜手推動「合作式 AI 主權」。掌握了自己的數位大腦，才能在 AI 的壟斷陰影下，保有一席自主且安全的生存空間。

> (採訪及整理：游羽棠。授權：[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.zh-hant))
